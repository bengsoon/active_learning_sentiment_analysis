{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning IMDB sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well-known and cliche IMDB dataset contains 50k reviews labeled with binary sentiment classification (`positive` or `negative`). It is usually used to train sentiment analysis for Natural Language Processing. However, in reality, we do not have the luxury of labeled data that is made available to us and the labeling process is a costly and tedious process. Active learning or sometimes known as \"human-in-the-loop\" learning are one of the tools that can effectively alleviate the costly process of data labeling. \n",
    "\n",
    "As such, we will take the existing IMDB data and simulate an active learning environment.  In our case, we will only have a limited set of initial labeled data to initiate the model development. At the same time, we will also have a pool of unlabeled data, which we will use in our active learning process.  \n",
    "\n",
    "To do this, we will need to prepare the existing 50k of the IMDB reviews data as follows:\n",
    "1. `Initial Training` set: we will allow ourselves to get **5,000** randomly-sampled **labeled examples** of the reviews for the initial development of the model.\n",
    "2. `Validation` set: we will set aside another **10,000** randomly-sampled **labeled examples** of the reviews for the validation of the model throughout the whole end-to-end active learning cycle. Ideally, we should update our `Validation` sets from time to time and monitor the model performance (for drift) from time to time, but for the simplicity of this project, we will assume that these initially 10k sampled examples will be statically used from the point of Initial Training stage to the end of Active Learning stage.     \n",
    "2. We will use the remaining **35,000** **unlabeled examples** as the `Unlabeled Pool` of dataset, where our active learning model will sample based on `uncertainty sampling` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure to check our environments are correct first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.1.1\n",
      "pandas==1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn\n",
    "!pip freeze | grep pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset to simulate active learning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Size: 50000 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path / \"IMDB_Dataset.csv\")\n",
    "print(\"Original Dataset Size:\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not spend too much time the EDA process of the dataset as we are focusing on the active learning MLOps workflow in this project. We will go ahead and sample the datasets for the different purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 5000 rows\n",
      "Original Dataset: 45000 rows\n"
     ]
    }
   ],
   "source": [
    "# sample 5,000 rows for training\n",
    "training_set = df.sample(5000)\n",
    "\n",
    "# remove the original data \n",
    "df = df.drop(training_set.index)\n",
    "\n",
    "# check to make sure the dataset is correctly sampled\n",
    "print(\"Training Set:\", len(training_set), \"rows\")\n",
    "print(\"Original Dataset:\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of the classes (`positive` vs `negative`) for the `training_set` are well-balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2511\n",
       "positive    2489\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "training_set.to_csv(data_path / \"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: 10000 rows\n",
      "Original Dataset: 35000 rows\n"
     ]
    }
   ],
   "source": [
    "# sample 10,000 rows for validation\n",
    "validation_set = df.sample(10000)\n",
    "\n",
    "# remove the original data \n",
    "df = df.drop(validation_set.index)\n",
    "\n",
    "# check to make sure the dataset is correctly sampled\n",
    "print(\"Validation Set:\", len(validation_set), \"rows\")\n",
    "print(\"Original Dataset:\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of the classes (`positive` vs `negative`) for the `validation_set` are also well-balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    5040\n",
       "positive    4960\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "validation_set.to_csv(data_path / \"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Unlabeled Pool: (35000, 1)\n"
     ]
    }
   ],
   "source": [
    "# use the remaining 35,000 examples as unlabeled pool of dataset\n",
    "unlabeled_pool = df.copy()\n",
    "\n",
    "# remove labels\n",
    "unlabeled_pool = unlabeled_pool.drop(columns=\"sentiment\")\n",
    "\n",
    "# check the shape\n",
    "print(\"Shape of Unlabeled Pool:\", unlabeled_pool.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the distribution of the classes (`positive` vs `negative`) for the remainder of the original `df` are also well-balanced, which meant that our `unlabeled_pool` is also balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    17551\n",
       "negative    17449\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "unlabeled_pool.to_csv(data_path / \"unlabeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('IMDB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af7a63553deff712e3f8fa7d2d5d7d35240d4ed129a65473b70a9331f46b6c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
