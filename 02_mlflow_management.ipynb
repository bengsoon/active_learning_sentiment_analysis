{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import mlflow\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "client = MlflowClient(\"http://127.0.0.1:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {}\n",
    "\n",
    "CONFIG[\"NORMALIZER\"] = \"stem\"\n",
    "\n",
    "def preprocessor(corpus: str or list) -> str:\n",
    "    '''\n",
    "    Preprocessor for the input features\n",
    "    '''\n",
    "\n",
    "    if type(corpus) == str:\n",
    "        corpus = [corpus]\n",
    "\n",
    "    preprocessed_corpus = []\n",
    "    for text in corpus:\n",
    "        # remove html tags\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "        # replace non-alphanumeric\n",
    "        text = re.sub(\"[^a-zA-Z0-9]+\", \" \", text)\n",
    "\n",
    "        # replace unnecessary whitespaces\n",
    "        text = re.sub(\"\\s+\", \" \", text)\n",
    "\n",
    "        normalizer = CONFIG[\"NORMALIZER\"]\n",
    "\n",
    "        if normalizer == \"stem\": \n",
    "            stemmer = PorterStemmer()\n",
    "            text = ' '.join([stemmer.stem(word) for word in word_tokenize(text)])\n",
    "        \n",
    "        elif normalizer == \"lemma\":\n",
    "            def pos_tagger(word):\n",
    "                \"\"\"\n",
    "                Obtains the Parts of Speech (POS) for NLTK's lemmatizer mapping\n",
    "                \"\"\"\n",
    "                tag = nltk.pos_tag([word])[0][1][0].lower()\n",
    "                tag_dict = {\"j\": wordnet.ADJ,\n",
    "                            \"n\": wordnet.NOUN,\n",
    "                            \"v\": wordnet.VERB,\n",
    "                            \"r\": wordnet.ADV}\n",
    "\n",
    "                # returns the pos tag, defaults to noun\n",
    "                return tag_dict.get(tag, wordnet.NOUN)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            text = ' '.join([lemmatizer.lemmatize(w, pos_tagger(w)) for w in word_tokenize(text)])\n",
    "        else:\n",
    "            raise Exception('Please enter CONFIG[\"NORMALIZER\"] as \"stem\" or \"lemma\"')\n",
    "        preprocessed_corpus.append(text)\n",
    "\n",
    "    return preprocessed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_runs(experiment_id:int = 1, max_results:int = 3) -> list:\n",
    "    '''\n",
    "    Gets `run_ids` for the top runs (`max_results`) with the highest accuracies\n",
    "\n",
    "    Returns list of run_ids with the highest accuracies\n",
    "    '''\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=str(experiment_id),\n",
    "        filter_string=\"\",\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=max_results,\n",
    "        order_by=[\"metrics.accuracy DESC\"]\n",
    "    )\n",
    "\n",
    "    run_ids = []\n",
    "\n",
    "    for run in runs:\n",
    "        print(f\"Run id: {run.info.run_id}, start_time: {run.info.start_time}\")\n",
    "        print(f\"Model_name: {run.data.tags['model_type']}, metrics: {run.data.metrics}\")\n",
    "        print(\"-\"*100)\n",
    "        run_ids.append(run.info.run_id)\n",
    "    \n",
    "    return run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 35b60b1ee6054fb5b78084524dfdd307, start_time: 1657177835952\n",
      "Model_name: Naive Bayes, metrics: {'accuracy': 0.8143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Run id: 202d3bb342ce46048b3bf3bf3dda6199, start_time: 1657180074773\n",
      "Model_name: SGDClassifier, metrics: {'accuracy': 0.8015}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Run id: e2eff7851b2947f5aee823422f992585, start_time: 1657177970430\n",
      "Model_name: Random Forest, metrics: {'accuracy': 0.7457}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "top_runs = get_top_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id:int, experiment_id:int =1,):\n",
    "    print(f\"{client.get_run(run_id).data.tags['model_type']} loaded (run_id: {run_id})\")\n",
    "    return mlflow.sklearn.load_model(f\"mlflow/mlruns/{experiment_id}/{run_id}/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes loaded (run_id: 35b60b1ee6054fb5b78084524dfdd307)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(top_runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes loaded (run_id: 35b60b1ee6054fb5b78084524dfdd307)\n",
      "[[0.75314729 0.24685271]]\n",
      "SGDClassifier loaded (run_id: 202d3bb342ce46048b3bf3bf3dda6199)\n",
      "[[0.75217694 0.24782306]]\n",
      "Random Forest loaded (run_id: e2eff7851b2947f5aee823422f992585)\n",
      "[[0.54692248 0.45307752]]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"First of all, let's get a few things straight here: a) I AM an anime fan- always has been as a matter of fact (I used to watch Speed Racer all the time in Preschool). b) I DO like several B-Movies because they're hilarious. c) I like the Godzilla movies- a lot.<br /><br />Moving on, when the movie first comes on, it seems like it's going to be your usual B-movie, down to the crappy FX, but all a sudden- BOOM! the anime comes on! This is when the movie goes WWWAAAAAYYYYY downhill.<br /><br />The animation is VERY bad & cheap, even worse than what I remember from SPEED RACER, for crissakes! In fact, it's so cheap, one of the few scenes from the movie I \"\"vividly\"\" remember is when a bunch of kids run out of a school... & it's the same kids over & over again! The FX are terrible, too; the dinosaurs look worse than Godzilla. In addition, the transition to live action to animation is unorganized, the dialogue & voices(especially the English dub that I viewed) was horrid & I was begging my dad to take the tape out of the DVD/ VHS player; The only thing that kept me surviving was cracking out jokes & comments like the robots & Joel/Mike on MST3K (you pick the season). Honestly, this is the only way to barely enjoy this movie & survive it at the same time.<br /><br />Heck, I'm planning to show this to another fellow otaku pal of mine on Halloween for a B-Movie night. Because it's stupid, pretty painful to watch & unintentionally hilarious at the same time, I'm giving this movie a 3/10, an improvement from the 0.5/10 I was originally going to give it.<br /><br />(According to my grading scale: 3/10 means Pretty much both boring & bad. As fun as counting to three unless you find a way to make fun of it, then it will become as fun as counting to 15.)\"\n",
    "\n",
    "for run in top_runs:\n",
    "    model = load_model(run)\n",
    "    print(model.predict_proba(preprocessor(test_sentence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('IMDB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af7a63553deff712e3f8fa7d2d5d7d35240d4ed129a65473b70a9331f46b6c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
